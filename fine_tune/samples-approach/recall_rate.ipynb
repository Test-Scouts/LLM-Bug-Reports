{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import util\n",
    "from torch import load, Tensor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/firefox_samples.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    samples_reports = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_encodings = \"data/encodings/fine-tuned-models/mpnet-lr-1e-8-m-5-e-3/mpnet-lr-1e-8-m-5-e-3-firefox-encodings-samples.pkl\"\n",
    "# file_path_encodings = \"data/encodings/mpnet-base/mpnet-base-firefox-encodings-samples.pkl\"\n",
    "with open(file_path_encodings, 'rb') as f:\n",
    "    samples_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rr_k_dict(prompt: Tensor, reports: pd.DataFrame, tensor_dict: dict, duplicate_ids: set, k: int):\n",
    "\n",
    "    similarity_scores = [] # array that will store tuples with a report id and its similarity score with the prompt\n",
    "\n",
    "    # iterate trough the dataframe\n",
    "    for bug_id in tensor_dict:\n",
    "\n",
    "        if bug_id in reports.index:\n",
    "\n",
    "            # append current report id and cosine similarity for the current report\n",
    "            # and the prompt descriptions the the selected model has generated\n",
    "            try:\n",
    "                similarity_scores.append(\n",
    "                    (\n",
    "                        bug_id,\n",
    "                        util.cos_sim(\n",
    "                            prompt,\n",
    "                            tensor_dict[bug_id]\n",
    "                        )[0].item()\n",
    "                    )\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # sort the similarity_scores list based on the similarity scores in descending order\n",
    "    similarity_scores.sort(key=lambda x: -x[1])\n",
    "\n",
    "    relevant_at_top_k = 0 # initialize counter of identified duplicates in top k as 0\n",
    "\n",
    "    order = 0\n",
    "    \n",
    "    \n",
    "    # iterate trough the tuples in the similarity_scores array. We skip the first since it will be the prompt itself\n",
    "    for value in similarity_scores[1:k+1]:\n",
    "        order += 1\n",
    "\n",
    "        # if the current report is a duplicate of the prompt, increase relevant_at_top_k by one\n",
    "        if value[0] in duplicate_ids:\n",
    "            relevant_at_top_k += 1\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    positives = len(duplicate_ids)\n",
    "    negatives = len(reports) - len(duplicate_ids)\n",
    "\n",
    "    false_positives = k - relevant_at_top_k\n",
    "    false_negatives = len(duplicate_ids) - relevant_at_top_k\n",
    "\n",
    "    true_positives = relevant_at_top_k\n",
    "    true_negatives = negatives - false_positives\n",
    "\n",
    "    \n",
    "    return [true_positives, false_negatives, false_positives, true_negatives]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalRRK2(reports: pd.DataFrame, relations: pd.DataFrame, tensor_dict_keys: list,  tensor_dict: dict, k: int):\n",
    "    confusion_matrix_dict = {}\n",
    "    for index in tensor_dict_keys:\n",
    "        if not (tensor_dict[index] is None):\n",
    "            duplicates_id = []\n",
    "\n",
    "            if index in relations.index:\n",
    "                duplicates_id = relations.loc[index]['duplicates']\n",
    "\n",
    "            if len(duplicates_id) > 0:\n",
    "                recall_rate = rr_k_dict(tensor_dict[index], reports, tensor_dict, set(duplicates_id), k)\n",
    "                confusion_matrix_dict[index] = recall_rate\n",
    "                #print(f'{index} -> {recall_rate}')\n",
    "\n",
    "    true_positives  = sum(x[0] for x in confusion_matrix_dict.values())\n",
    "    false_negatives = sum(x[1] for x in confusion_matrix_dict.values())\n",
    "    false_positives = sum(x[2] for x in confusion_matrix_dict.values())\n",
    "    true_negatives  = sum(x[3] for x in confusion_matrix_dict.values())\n",
    "    \n",
    "    return {\n",
    "        \"true_positives\" : true_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"true_negatives\" : true_negatives\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "418\n",
      "425\n",
      "428\n",
      "407\n",
      "476\n",
      "405\n",
      "430\n",
      "402\n",
      "352\n",
      "394\n",
      "429\n",
      "366\n",
      "440\n",
      "465\n",
      "409\n",
      "458\n",
      "474\n",
      "525\n",
      "390\n",
      "422\n",
      "453\n",
      "419\n",
      "459\n",
      "484\n",
      "433\n",
      "427\n",
      "401\n",
      "394\n",
      "422\n",
      "439\n",
      "446\n",
      "444\n",
      "435\n",
      "446\n",
      "413\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for key, value in samples_reports.items():\n",
    "\n",
    "    similarity_scores = [] # array that will store tuples with a report id and its similarity score with the prompt\n",
    "\n",
    "    emb = samples_embeddings[key]\n",
    "    emb_keys = [x for x in emb.keys()]\n",
    "\n",
    "    print(len(emb))\n",
    "\n",
    "    results[key] = generalRRK2(value[\"reports\"], value[\"relations\"], emb_keys, emb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_path = \"data/results/fine-tuned/firefox-fine-tuned-results.pkl\"\n",
    "with open(results_file_path, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_values = {}\n",
    "for key, value in results.items():\n",
    "    recall = value['true_positives'] / (value['true_positives']  + value['false_negatives'])\n",
    "    recall_values[key] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36.000000\n",
       "mean      0.738164\n",
       "std       0.056966\n",
       "min       0.637500\n",
       "25%       0.699929\n",
       "50%       0.727434\n",
       "75%       0.766169\n",
       "max       0.913208\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recal_series = pd.Series(recall_values)\n",
    "recal_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36.000000\n",
       "mean      0.724678\n",
       "std       0.054804\n",
       "min       0.639583\n",
       "25%       0.685408\n",
       "50%       0.719260\n",
       "75%       0.746369\n",
       "max       0.898113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recal_series = pd.Series(recall_values)\n",
    "recal_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7397660818713451,\n",
       " 2: 0.6928934010152284,\n",
       " 3: 0.7247474747474747,\n",
       " 4: 0.7041564792176039,\n",
       " 5: 0.7566844919786097,\n",
       " 6: 0.7096018735362998,\n",
       " 7: 0.6821705426356589,\n",
       " 8: 0.6762402088772846,\n",
       " 9: 0.7112299465240641,\n",
       " 10: 0.8981132075471698,\n",
       " 11: 0.7439024390243902,\n",
       " 12: 0.7537688442211056,\n",
       " 13: 0.7255520504731862,\n",
       " 14: 0.7628571428571429,\n",
       " 15: 0.6395833333333333,\n",
       " 16: 0.8006230529595015,\n",
       " 17: 0.6650366748166259,\n",
       " 18: 0.6556603773584906,\n",
       " 19: 0.6602564102564102,\n",
       " 20: 0.8074534161490683,\n",
       " 21: 0.7994579945799458,\n",
       " 22: 0.7008928571428571,\n",
       " 23: 0.7327327327327328,\n",
       " 24: 0.735632183908046,\n",
       " 25: 0.6636971046770601,\n",
       " 26: 0.7252124645892352,\n",
       " 27: 0.7146401985111662,\n",
       " 28: 0.6798866855524079,\n",
       " 29: 0.8353658536585366,\n",
       " 30: 0.7043010752688172,\n",
       " 31: 0.7263681592039801,\n",
       " 32: 0.6744791666666666,\n",
       " 33: 0.7238805970149254,\n",
       " 34: 0.6864864864864865,\n",
       " 35: 0.6948717948717948,\n",
       " 36: 0.7802197802197802}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1.335938\n",
       "2     1.417266\n",
       "3     1.337838\n",
       "4     1.377104\n",
       "5     1.303136\n",
       "6     1.377419\n",
       "7     1.438662\n",
       "8     1.450758\n",
       "9     1.411321\n",
       "10    1.095041\n",
       "11    1.322581\n",
       "12    1.283871\n",
       "13    1.372294\n",
       "14    1.277372\n",
       "15    1.568627\n",
       "16    1.220532\n",
       "17    1.471223\n",
       "18    1.503546\n",
       "19    1.490446\n",
       "20    1.219697\n",
       "21    1.217822\n",
       "22    1.395639\n",
       "23    1.305882\n",
       "24    1.342593\n",
       "25    1.491694\n",
       "26    1.368217\n",
       "27    1.384880\n",
       "28    1.429150\n",
       "29    1.184116\n",
       "30    1.409091\n",
       "31    1.348993\n",
       "32    1.449057\n",
       "33    1.344482\n",
       "34    1.428571\n",
       "35    1.407942\n",
       "36    1.255172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse = 1 / recal_series\n",
    "inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36.000000\n",
       "mean      1.362166\n",
       "std       0.099894\n",
       "min       1.095041\n",
       "25%       1.305196\n",
       "50%       1.374699\n",
       "75%       1.428716\n",
       "max       1.568627\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36.000000\n",
       "mean      1.387140\n",
       "std       0.098676\n",
       "min       1.113445\n",
       "25%       1.339863\n",
       "50%       1.390374\n",
       "75%       1.458997\n",
       "max       1.563518\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'true_positives': 253,\n",
       "  'false_negatives': 89,\n",
       "  'false_positives': 747,\n",
       "  'true_negatives': 42511},\n",
       " 2: {'true_positives': 273,\n",
       "  'false_negatives': 121,\n",
       "  'false_positives': 727,\n",
       "  'true_negatives': 40679},\n",
       " 3: {'true_positives': 287,\n",
       "  'false_negatives': 109,\n",
       "  'false_positives': 713,\n",
       "  'true_negatives': 41391},\n",
       " 4: {'true_positives': 288,\n",
       "  'false_negatives': 121,\n",
       "  'false_positives': 712,\n",
       "  'true_negatives': 41679},\n",
       " 5: {'true_positives': 283,\n",
       "  'false_negatives': 91,\n",
       "  'false_positives': 717,\n",
       "  'true_negatives': 39609},\n",
       " 6: {'true_positives': 303,\n",
       "  'false_negatives': 124,\n",
       "  'false_positives': 697,\n",
       "  'true_negatives': 46476},\n",
       " 7: {'true_positives': 264,\n",
       "  'false_negatives': 123,\n",
       "  'false_positives': 736,\n",
       "  'true_negatives': 39377},\n",
       " 8: {'true_positives': 259,\n",
       "  'false_negatives': 124,\n",
       "  'false_positives': 741,\n",
       "  'true_negatives': 41876},\n",
       " 9: {'true_positives': 266,\n",
       "  'false_negatives': 108,\n",
       "  'false_positives': 734,\n",
       "  'true_negatives': 39092},\n",
       " 10: {'true_positives': 238,\n",
       "  'false_negatives': 27,\n",
       "  'false_positives': 762,\n",
       "  'true_negatives': 34173},\n",
       " 11: {'true_positives': 244,\n",
       "  'false_negatives': 84,\n",
       "  'false_positives': 756,\n",
       "  'true_negatives': 38316},\n",
       " 12: {'true_positives': 300,\n",
       "  'false_negatives': 98,\n",
       "  'false_positives': 700,\n",
       "  'true_negatives': 41802},\n",
       " 13: {'true_positives': 230,\n",
       "  'false_negatives': 87,\n",
       "  'false_positives': 770,\n",
       "  'true_negatives': 35513},\n",
       " 14: {'true_positives': 267,\n",
       "  'false_negatives': 83,\n",
       "  'false_positives': 733,\n",
       "  'true_negatives': 42917},\n",
       " 15: {'true_positives': 307,\n",
       "  'false_negatives': 173,\n",
       "  'false_positives': 693,\n",
       "  'true_negatives': 45327},\n",
       " 16: {'true_positives': 257,\n",
       "  'false_negatives': 64,\n",
       "  'false_positives': 743,\n",
       "  'true_negatives': 39836},\n",
       " 17: {'true_positives': 272,\n",
       "  'false_negatives': 137,\n",
       "  'false_positives': 728,\n",
       "  'true_negatives': 44663},\n",
       " 18: {'true_positives': 278,\n",
       "  'false_negatives': 146,\n",
       "  'false_positives': 722,\n",
       "  'true_negatives': 46254},\n",
       " 19: {'true_positives': 309,\n",
       "  'false_negatives': 159,\n",
       "  'false_positives': 691,\n",
       "  'true_negatives': 51341},\n",
       " 20: {'true_positives': 260,\n",
       "  'false_negatives': 62,\n",
       "  'false_positives': 740,\n",
       "  'true_negatives': 37938},\n",
       " 21: {'true_positives': 295,\n",
       "  'false_negatives': 74,\n",
       "  'false_positives': 705,\n",
       "  'true_negatives': 41126},\n",
       " 22: {'true_positives': 314,\n",
       "  'false_negatives': 134,\n",
       "  'false_positives': 686,\n",
       "  'true_negatives': 44166},\n",
       " 23: {'true_positives': 244,\n",
       "  'false_negatives': 89,\n",
       "  'false_positives': 756,\n",
       "  'true_negatives': 40811},\n",
       " 24: {'true_positives': 320,\n",
       "  'false_negatives': 115,\n",
       "  'false_positives': 680,\n",
       "  'true_negatives': 44785},\n",
       " 25: {'true_positives': 298,\n",
       "  'false_negatives': 151,\n",
       "  'false_positives': 702,\n",
       "  'true_negatives': 47249},\n",
       " 26: {'true_positives': 256,\n",
       "  'false_negatives': 97,\n",
       "  'false_positives': 744,\n",
       "  'true_negatives': 42203},\n",
       " 27: {'true_positives': 288,\n",
       "  'false_negatives': 115,\n",
       "  'false_positives': 712,\n",
       "  'true_negatives': 41585},\n",
       " 28: {'true_positives': 240,\n",
       "  'false_negatives': 113,\n",
       "  'false_positives': 760,\n",
       "  'true_negatives': 38987},\n",
       " 29: {'true_positives': 274,\n",
       "  'false_negatives': 54,\n",
       "  'false_positives': 726,\n",
       "  'true_negatives': 38346},\n",
       " 30: {'true_positives': 262,\n",
       "  'false_negatives': 110,\n",
       "  'false_positives': 738,\n",
       "  'true_negatives': 41090},\n",
       " 31: {'true_positives': 292,\n",
       "  'false_negatives': 110,\n",
       "  'false_positives': 708,\n",
       "  'true_negatives': 42790},\n",
       " 32: {'true_positives': 259,\n",
       "  'false_negatives': 125,\n",
       "  'false_positives': 741,\n",
       "  'true_negatives': 43475},\n",
       " 33: {'true_positives': 291,\n",
       "  'false_negatives': 111,\n",
       "  'false_positives': 709,\n",
       "  'true_negatives': 43289},\n",
       " 34: {'true_positives': 254,\n",
       "  'false_negatives': 116,\n",
       "  'false_positives': 746,\n",
       "  'true_negatives': 42384},\n",
       " 35: {'true_positives': 271,\n",
       "  'false_negatives': 119,\n",
       "  'false_positives': 729,\n",
       "  'true_negatives': 43481},\n",
       " 36: {'true_positives': 284,\n",
       "  'false_negatives': 80,\n",
       "  'false_positives': 716,\n",
       "  'true_negatives': 40220}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
